#!/usr/bin/env python3
"""
Stage A åŸºçº¿æ‰§è¡Œå™¨
ä½¿ç”¨Task 1è®­ç»ƒå¥½çš„æ¨¡å‹ï¼Œå¯¹æ‰€æœ‰è®­ç»ƒç›¸æœºåº”ç”¨Reinhardé¢œè‰²è¿ç§»
"""

import os
import sys
import json
import argparse
import numpy as np
from pathlib import Path
import torch
from PIL import Image
import cv2

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append('.')

# å¯¼å…¥ä¸“å®¶æä¾›çš„æ¨¡å—
from stage_a_reinhard import reinhard_color_transfer_linear, srgb_to_linear, linear_to_srgb, create_mask
from metrics_color import compute_color_metrics

# å¯¼å…¥3DGSç›¸å…³æ¨¡å—
from scene import Scene, GaussianModel
from gaussian_renderer import render
from utils.image_utils import psnr
from arguments import ModelParams, PipelineParams, get_combined_args

def load_trained_model(model_path, iteration):
    """åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹"""
    print(f"[Stage A] åŠ è½½æ¨¡å‹: {model_path} @ iteration {iteration}")
    
    # è¯»å–ä¿å­˜çš„é…ç½®
    cfg_file = os.path.join(model_path, "cfg_args")
    if not os.path.exists(cfg_file):
        raise FileNotFoundError(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {cfg_file}")
    
    with open(cfg_file, 'r') as f:
        cfg_str = f.read()
    
    # æ‰‹åŠ¨è§£æé…ç½®ï¼ˆç®€å•çš„é”®å€¼å¯¹æå–ï¼‰
    import re
    cfg_dict = {}
    # æå–source_path
    match = re.search(r"source_path='([^']+)'", cfg_str)
    if match:
        cfg_dict['source_path'] = match.group(1)
    
    # æå–å…¶ä»–å‚æ•°
    for key in ['sh_degree', 'appearance_enabled', 'appearance_n_fourier_freqs', 'appearance_embedding_dim',
                'images', 'resolution', 'white_background', 'data_device', 'eval', 'load_allres']:
        match = re.search(rf"{key}=([^,\)]+)", cfg_str)
        if match:
            value = match.group(1).strip().strip("'\"")
            # è½¬æ¢ç±»å‹
            if value in ['True', 'False']:
                cfg_dict[key] = value == 'True'
            elif value.isdigit() or (value.startswith('-') and value[1:].isdigit()):
                cfg_dict[key] = int(value)
            else:
                cfg_dict[key] = value
    
    # åˆ›å»ºé«˜æ–¯æ¨¡å‹
    gaussians = GaussianModel(
        sh_degree=cfg_dict.get('sh_degree', 0),
        appearance_enabled=cfg_dict.get('appearance_enabled', False),
        appearance_n_fourier_freqs=cfg_dict.get('appearance_n_fourier_freqs', 0),
        appearance_embedding_dim=cfg_dict.get('appearance_embedding_dim', 0)
    )
    
    # åˆ›å»ºæ¨¡å‹å‚æ•°å¯¹è±¡
    class ModelArgs:
        def __init__(self, cfg_dict, model_path):
            self.model_path = model_path
            self.source_path = cfg_dict.get('source_path', '')
            self.images = cfg_dict.get('images', 'images')
            self.resolution = cfg_dict.get('resolution', -1)
            self.white_background = cfg_dict.get('white_background', False)
            self.data_device = cfg_dict.get('data_device', 'cuda')
            self.eval = cfg_dict.get('eval', False)
            self.load_allres = cfg_dict.get('load_allres', False)
    
    model_args = ModelArgs(cfg_dict, model_path)
    
    # åŠ è½½åœºæ™¯
    scene = Scene(model_args, gaussians, load_iteration=iteration, shuffle=False)
    
    print(f"[Stage A] æ¨¡å‹åŠ è½½å®Œæˆï¼Œé«˜æ–¯æ•°é‡: {len(gaussians._xyz)}")
    return scene, gaussians

def render_camera(camera, gaussians, pipeline_args, background, kernel_size=0.1):
    """æ¸²æŸ“å•ä¸ªç›¸æœº"""
    with torch.no_grad():
        render_pkg = render(camera, gaussians, pipeline_args, background, kernel_size=kernel_size)
        image = render_pkg["render"]
        alpha = render_pkg.get("alpha", None)
    return image, alpha

def process_single_camera(camera, gaussians, pipeline_args, background, output_dir, cam_id):
    """å¤„ç†å•ä¸ªç›¸æœºçš„é¢œè‰²è¿ç§»"""
    print(f"[Stage A] å¤„ç†ç›¸æœº {cam_id}...")
    
    # æ¸²æŸ“
    render_image, alpha = render_camera(camera, gaussians, pipeline_args, background)
    
    # è½¬æ¢ä¸ºnumpy (CHW -> HWC)
    render_np = render_image.detach().cpu().numpy().transpose(1, 2, 0)  # (H, W, 3)
    if alpha is not None:
        alpha_np = alpha.detach().cpu().numpy().squeeze()  # (H, W)
    else:
        alpha_np = np.ones(render_np.shape[:2])
    
    # GTå›¾åƒï¼ˆå·²ç»æ˜¯Linear RGBï¼ŒTask 1å·²ä¿®å¤ï¼‰
    gt_image = camera.original_image.cuda()
    gt_np = gt_image.detach().cpu().numpy().transpose(1, 2, 0)  # (H, W, 3)
    
    # åˆ›å»ºæœ‰æ•ˆåƒç´ mask
    mask = create_mask(alpha_np, render_np)
    valid_pixels = np.sum(mask)
    print(f"  æœ‰æ•ˆåƒç´ : {valid_pixels} / {mask.size} ({100*valid_pixels/mask.size:.1f}%)")
    
    if valid_pixels < 1000:
        print(f"  âš ï¸  æœ‰æ•ˆåƒç´ å¤ªå°‘ï¼Œè·³è¿‡ç›¸æœº {cam_id}")
        return None
    
    # è®¡ç®—åŸå§‹æŒ‡æ ‡
    original_metrics = compute_color_metrics(render_np, gt_np, mask)
    print(f"  åŸå§‹ - PSNR: {original_metrics['psnr']:.2f} dB, Î”E00: {original_metrics['delta_e00']['median']:.2f}")
    
    # åº”ç”¨Reinhardé¢œè‰²è¿ç§»
    calibrated_np = reinhard_color_transfer_linear(render_np, gt_np, mask)
    
    # è®¡ç®—æ ¡æ­£åæŒ‡æ ‡
    calibrated_metrics = compute_color_metrics(calibrated_np, gt_np, mask)
    print(f"  æ ¡æ­£å - PSNR: {calibrated_metrics['psnr']:.2f} dB, Î”E00: {calibrated_metrics['delta_e00']['median']:.2f}")
    
    # è®¡ç®—æå‡
    psnr_improvement = calibrated_metrics['psnr'] - original_metrics['psnr']
    delta_e_improvement = original_metrics['delta_e00']['median'] - calibrated_metrics['delta_e00']['median']
    print(f"  æå‡ - PSNR: +{psnr_improvement:.2f} dB, Î”E00: -{delta_e_improvement:.2f}")
    
    # ä¿å­˜å¯¹æ¯”å›¾
    vis_dir = Path(output_dir) / "vis"
    vis_dir.mkdir(exist_ok=True)
    
    # è½¬æ¢ä¸ºsRGBç”¨äºä¿å­˜
    render_srgb = linear_to_srgb(render_np)
    gt_srgb = linear_to_srgb(gt_np)
    calibrated_srgb = linear_to_srgb(calibrated_np)
    
    # åˆ›å»ºå¯¹æ¯”å›¾
    comparison = np.concatenate([render_srgb, gt_srgb, calibrated_srgb], axis=1)
    Image.fromarray(comparison).save(vis_dir / f"cam_{cam_id:03d}_comparison.png")
    
    # ä¿å­˜Î”Eè¯¯å·®å›¾
    delta_e_map = calibrated_metrics['delta_e00']['map']
    delta_e_vis = np.clip(delta_e_map / 10.0 * 255, 0, 255).astype(np.uint8)
    delta_e_colored = cv2.applyColorMap(delta_e_vis, cv2.COLORMAP_JET)
    cv2.imwrite(str(vis_dir / f"cam_{cam_id:03d}_delta_e.png"), delta_e_colored)
    
    return {
        'camera_id': cam_id,
        'valid_pixels': int(valid_pixels),
        'original_psnr': float(original_metrics['psnr']),
        'calibrated_psnr': float(calibrated_metrics['psnr']),
        'psnr_improvement': float(psnr_improvement),
        'original_delta_e00_median': float(original_metrics['delta_e00']['median']),
        'calibrated_delta_e00_median': float(calibrated_metrics['delta_e00']['median']),
        'delta_e_improvement': float(delta_e_improvement)
    }

def main():
    parser = argparse.ArgumentParser(description="Stage A åŸºçº¿æ‰§è¡Œå™¨")
    parser.add_argument('--model_path', type=str, required=True, help='æ¨¡å‹è·¯å¾„')
    parser.add_argument('--iteration', type=int, default=3000, help='è¿­ä»£æ•°')
    parser.add_argument('--output', type=str, required=True, help='è¾“å‡ºè·¯å¾„')
    args = parser.parse_args()
    
    print("========================================================================")
    print("Task 2 - Stage A åŸºçº¿æ‰§è¡Œå™¨")
    print("========================================================================")
    print(f"æ¨¡å‹: {args.model_path}")
    print(f"è¿­ä»£: {args.iteration}")
    print(f"è¾“å‡º: {args.output}")
    print("")
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = Path(args.output)
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # åŠ è½½æ¨¡å‹
    scene, gaussians = load_trained_model(args.model_path, args.iteration)
    
    # è®¾ç½®æ¸²æŸ“å‚æ•°
    class PipelineArgs:
        def __init__(self):
            self.convert_SHs_python = False
            self.compute_cov3D_python = False
            self.debug = False
    
    pipeline_args = PipelineArgs()
    background = torch.tensor([0, 0, 0], dtype=torch.float32, device="cuda")
    
    # è·å–è®­ç»ƒç›¸æœº
    train_cameras = scene.getTrainCameras()
    print(f"[Stage A] å¤„ç† {len(train_cameras)} ä¸ªè®­ç»ƒç›¸æœº")
    
    # å¤„ç†æ‰€æœ‰ç›¸æœº
    results = []
    for i, camera in enumerate(train_cameras):
        try:
            result = process_single_camera(
                camera, gaussians, pipeline_args, 
                background, args.output, i
            )
            if result:
                results.append(result)
        except Exception as e:
            print(f"  âŒ ç›¸æœº {i} å¤„ç†å¤±è´¥: {e}")
            continue
    
    if not results:
        print("âŒ æ²¡æœ‰æˆåŠŸå¤„ç†çš„ç›¸æœº")
        return
    
    # è®¡ç®—æ•´ä½“ç»Ÿè®¡
    avg_psnr_improvement = np.mean([r['psnr_improvement'] for r in results])
    avg_delta_e00_median = np.mean([r['calibrated_delta_e00_median'] for r in results])
    
    summary = {
        'num_cameras': len(results),
        'avg_psnr_improvement': float(avg_psnr_improvement),
        'avg_delta_e00_median': float(avg_delta_e00_median),
        'per_camera_results': results
    }
    
    # ä¿å­˜ç»“æœ
    with open(output_dir / "results.json", 'w') as f:
        json.dump(summary, f, indent=2)
    
    print("")
    print("========================================================================")
    print("Stage A å®Œæˆ")
    print("========================================================================")
    print(f"å¤„ç†ç›¸æœºæ•°: {len(results)}")
    print(f"å¹³å‡PSNRæå‡: {avg_psnr_improvement:.2f} dB")
    print(f"å¹³å‡Î”E00: {avg_delta_e00_median:.2f}")
    
    # Gate T2-1éªŒè¯
    psnr_ok = avg_psnr_improvement >= 1.0
    delta_e_ok = avg_delta_e00_median <= 4.0
    
    print("")
    print("Gate T2-1éªŒè¯:")
    print(f"  PSNRæå‡â‰¥1.0dB: {'âœ…' if psnr_ok else 'âŒ'} ({avg_psnr_improvement:.2f} dB)")
    print(f"  Î”E00â‰¤4.0: {'âœ…' if delta_e_ok else 'âŒ'} ({avg_delta_e00_median:.2f})")
    
    if psnr_ok and delta_e_ok:
        print("  ğŸ‰ Gate T2-1 é€šè¿‡ï¼å¯ä»¥è¿›å…¥Stage B")
    else:
        print("  âš ï¸  Gate T2-1 æœªé€šè¿‡ï¼Œéœ€è¦è°ƒæ•´å‚æ•°")
    
    print(f"")
    print(f"ç»“æœå·²ä¿å­˜: {output_dir / 'results.json'}")
    print(f"å¯¹æ¯”å›¾: {output_dir / 'vis/'}")

if __name__ == "__main__":
    main()
